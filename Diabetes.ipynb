{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5dbe7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f5b6f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1e0f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214413cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73987364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17]\n",
      "*******************************************************\n",
      "Glucose [0, 44, 56, 57, 61, 62, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199]\n",
      "*******************************************************\n",
      "BloodPressure [0, 24, 30, 38, 40, 44, 46, 48, 50, 52, 54, 55, 56, 58, 60, 61, 62, 64, 65, 66, 68, 70, 72, 74, 75, 76, 78, 80, 82, 84, 85, 86, 88, 90, 92, 94, 95, 96, 98, 100, 102, 104, 106, 108, 110, 114, 122]\n",
      "*******************************************************\n",
      "SkinThickness [0, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 60, 63, 99]\n",
      "*******************************************************\n",
      "Insulin [0, 14, 15, 16, 18, 22, 23, 25, 29, 32, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 99, 100, 105, 106, 108, 110, 112, 114, 115, 116, 119, 120, 122, 125, 126, 127, 128, 129, 130, 132, 135, 140, 142, 144, 145, 146, 148, 150, 152, 155, 156, 158, 159, 160, 165, 166, 167, 168, 170, 171, 175, 176, 178, 180, 182, 183, 184, 185, 188, 190, 191, 192, 193, 194, 196, 200, 204, 205, 207, 210, 215, 220, 225, 228, 230, 231, 235, 237, 240, 245, 249, 250, 255, 258, 265, 270, 271, 272, 274, 275, 277, 278, 280, 284, 285, 291, 293, 300, 304, 310, 318, 321, 325, 326, 328, 330, 335, 342, 360, 370, 375, 387, 392, 402, 415, 440, 465, 474, 478, 480, 485, 495, 510, 540, 543, 545, 579, 600, 680, 744, 846]\n",
      "*******************************************************\n",
      "BMI [0.0, 18.2, 18.4, 19.1, 19.3, 19.4, 19.5, 19.6, 19.9, 20.0, 20.1, 20.4, 20.8, 21.0, 21.1, 21.2, 21.7, 21.8, 21.9, 22.1, 22.2, 22.3, 22.4, 22.5, 22.6, 22.7, 22.9, 23.0, 23.1, 23.2, 23.3, 23.4, 23.5, 23.6, 23.7, 23.8, 23.9, 24.0, 24.1, 24.2, 24.3, 24.4, 24.5, 24.6, 24.7, 24.8, 24.9, 25.0, 25.1, 25.2, 25.3, 25.4, 25.5, 25.6, 25.8, 25.9, 26.0, 26.1, 26.2, 26.3, 26.4, 26.5, 26.6, 26.7, 26.8, 26.9, 27.0, 27.1, 27.2, 27.3, 27.4, 27.5, 27.6, 27.7, 27.8, 27.9, 28.0, 28.1, 28.2, 28.3, 28.4, 28.5, 28.6, 28.7, 28.8, 28.9, 29.0, 29.2, 29.3, 29.5, 29.6, 29.7, 29.8, 29.9, 30.0, 30.1, 30.2, 30.3, 30.4, 30.5, 30.7, 30.8, 30.9, 31.0, 31.1, 31.2, 31.3, 31.6, 31.9, 32.0, 32.1, 32.2, 32.3, 32.4, 32.5, 32.6, 32.7, 32.8, 32.9, 33.1, 33.2, 33.3, 33.5, 33.6, 33.7, 33.8, 33.9, 34.0, 34.1, 34.2, 34.3, 34.4, 34.5, 34.6, 34.7, 34.8, 34.9, 35.0, 35.1, 35.2, 35.3, 35.4, 35.5, 35.6, 35.7, 35.8, 35.9, 36.0, 36.1, 36.2, 36.3, 36.4, 36.5, 36.6, 36.7, 36.8, 36.9, 37.0, 37.1, 37.2, 37.3, 37.4, 37.5, 37.6, 37.7, 37.8, 37.9, 38.0, 38.1, 38.2, 38.3, 38.4, 38.5, 38.6, 38.7, 38.8, 38.9, 39.0, 39.1, 39.2, 39.3, 39.4, 39.5, 39.6, 39.7, 39.8, 39.9, 40.0, 40.1, 40.2, 40.5, 40.6, 40.7, 40.8, 40.9, 41.0, 41.2, 41.3, 41.5, 41.8, 42.0, 42.1, 42.2, 42.3, 42.4, 42.6, 42.7, 42.8, 42.9, 43.1, 43.2, 43.3, 43.4, 43.5, 43.6, 44.0, 44.1, 44.2, 44.5, 44.6, 45.0, 45.2, 45.3, 45.4, 45.5, 45.6, 45.7, 45.8, 46.1, 46.2, 46.3, 46.5, 46.7, 46.8, 47.9, 48.3, 48.8, 49.3, 49.6, 49.7, 50.0, 52.3, 52.9, 53.2, 55.0, 57.3, 59.4, 67.1]\n",
      "*******************************************************\n",
      "DiabetesPedigreeFunction [0.078, 0.084, 0.085, 0.088, 0.089, 0.092, 0.096, 0.1, 0.101, 0.102, 0.107, 0.108, 0.115, 0.118, 0.121, 0.122, 0.123, 0.126, 0.127, 0.128, 0.129, 0.13, 0.133, 0.134, 0.135, 0.136, 0.137, 0.138, 0.14, 0.141, 0.142, 0.143, 0.144, 0.145, 0.147, 0.148, 0.149, 0.15, 0.151, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.17, 0.171, 0.173, 0.174, 0.175, 0.176, 0.177, 0.178, 0.179, 0.18, 0.181, 0.182, 0.183, 0.186, 0.187, 0.188, 0.189, 0.19, 0.191, 0.192, 0.194, 0.196, 0.197, 0.198, 0.199, 0.2, 0.201, 0.203, 0.204, 0.205, 0.206, 0.207, 0.209, 0.21, 0.212, 0.215, 0.217, 0.218, 0.219, 0.22, 0.221, 0.222, 0.223, 0.225, 0.226, 0.227, 0.229, 0.23, 0.231, 0.232, 0.233, 0.234, 0.235, 0.236, 0.237, 0.238, 0.239, 0.24, 0.241, 0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.251, 0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26, 0.261, 0.262, 0.263, 0.264, 0.265, 0.267, 0.268, 0.269, 0.27, 0.271, 0.272, 0.277, 0.278, 0.279, 0.28, 0.282, 0.283, 0.284, 0.285, 0.286, 0.287, 0.289, 0.29, 0.292, 0.293, 0.294, 0.295, 0.296, 0.297, 0.299, 0.3, 0.302, 0.303, 0.304, 0.305, 0.306, 0.307, 0.313, 0.314, 0.315, 0.317, 0.318, 0.319, 0.323, 0.324, 0.325, 0.326, 0.328, 0.329, 0.33, 0.331, 0.332, 0.334, 0.335, 0.336, 0.337, 0.338, 0.34, 0.341, 0.342, 0.343, 0.344, 0.345, 0.346, 0.347, 0.349, 0.351, 0.352, 0.355, 0.356, 0.358, 0.361, 0.362, 0.364, 0.365, 0.366, 0.368, 0.37, 0.371, 0.374, 0.375, 0.376, 0.378, 0.38, 0.381, 0.382, 0.383, 0.385, 0.388, 0.389, 0.391, 0.393, 0.394, 0.395, 0.396, 0.398, 0.399, 0.4, 0.401, 0.402, 0.403, 0.404, 0.407, 0.408, 0.409, 0.411, 0.412, 0.415, 0.416, 0.417, 0.419, 0.42, 0.421, 0.422, 0.423, 0.426, 0.427, 0.43, 0.431, 0.432, 0.433, 0.434, 0.435, 0.439, 0.441, 0.443, 0.444, 0.446, 0.447, 0.451, 0.452, 0.453, 0.454, 0.455, 0.457, 0.46, 0.463, 0.464, 0.465, 0.466, 0.467, 0.471, 0.472, 0.479, 0.482, 0.483, 0.484, 0.485, 0.487, 0.488, 0.491, 0.493, 0.495, 0.496, 0.497, 0.498, 0.499, 0.501, 0.502, 0.503, 0.507, 0.509, 0.51, 0.512, 0.514, 0.515, 0.516, 0.52, 0.525, 0.526, 0.527, 0.528, 0.529, 0.532, 0.534, 0.536, 0.537, 0.539, 0.542, 0.543, 0.545, 0.546, 0.547, 0.549, 0.551, 0.554, 0.557, 0.559, 0.56, 0.561, 0.564, 0.565, 0.569, 0.571, 0.572, 0.575, 0.578, 0.58, 0.582, 0.583, 0.586, 0.587, 0.588, 0.591, 0.593, 0.595, 0.597, 0.598, 0.6, 0.601, 0.605, 0.607, 0.61, 0.612, 0.613, 0.614, 0.615, 0.619, 0.624, 0.626, 0.627, 0.629, 0.63, 0.631, 0.637, 0.64, 0.645, 0.646, 0.647, 0.649, 0.652, 0.654, 0.655, 0.658, 0.66, 0.661, 0.665, 0.666, 0.672, 0.673, 0.674, 0.677, 0.678, 0.68, 0.682, 0.686, 0.687, 0.692, 0.693, 0.695, 0.696, 0.698, 0.699, 0.702, 0.703, 0.704, 0.705, 0.709, 0.711, 0.717, 0.718, 0.719, 0.721, 0.722, 0.725, 0.727, 0.73, 0.731, 0.732, 0.733, 0.734, 0.735, 0.738, 0.741, 0.742, 0.743, 0.744, 0.745, 0.748, 0.757, 0.759, 0.761, 0.766, 0.767, 0.771, 0.773, 0.785, 0.787, 0.801, 0.803, 0.804, 0.805, 0.808, 0.813, 0.816, 0.817, 0.821, 0.825, 0.826, 0.828, 0.831, 0.832, 0.833, 0.839, 0.84, 0.845, 0.851, 0.855, 0.856, 0.867, 0.871, 0.874, 0.875, 0.878, 0.88, 0.881, 0.886, 0.892, 0.893, 0.904, 0.905, 0.917, 0.925, 0.926, 0.93, 0.932, 0.933, 0.944, 0.947, 0.949, 0.955, 0.956, 0.962, 0.966, 0.968, 0.97, 0.997, 1.001, 1.021, 1.022, 1.034, 1.057, 1.072, 1.076, 1.095, 1.096, 1.101, 1.114, 1.127, 1.136, 1.138, 1.144, 1.154, 1.159, 1.162, 1.174, 1.182, 1.189, 1.191, 1.213, 1.222, 1.224, 1.251, 1.258, 1.268, 1.282, 1.292, 1.318, 1.321, 1.353, 1.39, 1.391, 1.394, 1.4, 1.441, 1.461, 1.476, 1.6, 1.698, 1.699, 1.731, 1.781, 1.893, 2.137, 2.288, 2.329, 2.42]\n",
      "*******************************************************\n",
      "Age [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 81]\n",
      "*******************************************************\n",
      "Outcome [0, 1]\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,sorted(df[i].unique()))\n",
    "    print(\"*\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c87f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_zero=[\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n",
    "\n",
    "for i in columns_with_zero:\n",
    "    df[i]=np.where(df[i]==0,df[i].median(),df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63c7907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17]\n",
      "*******************************************************\n",
      "Glucose [44.0, 56.0, 57.0, 61.0, 62.0, 65.0, 67.0, 68.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0]\n",
      "*******************************************************\n",
      "BloodPressure [24.0, 30.0, 38.0, 40.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 55.0, 56.0, 58.0, 60.0, 61.0, 62.0, 64.0, 65.0, 66.0, 68.0, 70.0, 72.0, 74.0, 75.0, 76.0, 78.0, 80.0, 82.0, 84.0, 85.0, 86.0, 88.0, 90.0, 92.0, 94.0, 95.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 114.0, 122.0]\n",
      "*******************************************************\n",
      "SkinThickness [7.0, 8.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 54.0, 56.0, 60.0, 63.0, 99.0]\n",
      "*******************************************************\n",
      "Insulin [14.0, 15.0, 16.0, 18.0, 22.0, 23.0, 25.0, 29.0, 30.5, 32.0, 36.0, 37.0, 38.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 94.0, 95.0, 96.0, 99.0, 100.0, 105.0, 106.0, 108.0, 110.0, 112.0, 114.0, 115.0, 116.0, 119.0, 120.0, 122.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 132.0, 135.0, 140.0, 142.0, 144.0, 145.0, 146.0, 148.0, 150.0, 152.0, 155.0, 156.0, 158.0, 159.0, 160.0, 165.0, 166.0, 167.0, 168.0, 170.0, 171.0, 175.0, 176.0, 178.0, 180.0, 182.0, 183.0, 184.0, 185.0, 188.0, 190.0, 191.0, 192.0, 193.0, 194.0, 196.0, 200.0, 204.0, 205.0, 207.0, 210.0, 215.0, 220.0, 225.0, 228.0, 230.0, 231.0, 235.0, 237.0, 240.0, 245.0, 249.0, 250.0, 255.0, 258.0, 265.0, 270.0, 271.0, 272.0, 274.0, 275.0, 277.0, 278.0, 280.0, 284.0, 285.0, 291.0, 293.0, 300.0, 304.0, 310.0, 318.0, 321.0, 325.0, 326.0, 328.0, 330.0, 335.0, 342.0, 360.0, 370.0, 375.0, 387.0, 392.0, 402.0, 415.0, 440.0, 465.0, 474.0, 478.0, 480.0, 485.0, 495.0, 510.0, 540.0, 543.0, 545.0, 579.0, 600.0, 680.0, 744.0, 846.0]\n",
      "*******************************************************\n",
      "BMI [18.2, 18.4, 19.1, 19.3, 19.4, 19.5, 19.6, 19.9, 20.0, 20.1, 20.4, 20.8, 21.0, 21.1, 21.2, 21.7, 21.8, 21.9, 22.1, 22.2, 22.3, 22.4, 22.5, 22.6, 22.7, 22.9, 23.0, 23.1, 23.2, 23.3, 23.4, 23.5, 23.6, 23.7, 23.8, 23.9, 24.0, 24.1, 24.2, 24.3, 24.4, 24.5, 24.6, 24.7, 24.8, 24.9, 25.0, 25.1, 25.2, 25.3, 25.4, 25.5, 25.6, 25.8, 25.9, 26.0, 26.1, 26.2, 26.3, 26.4, 26.5, 26.6, 26.7, 26.8, 26.9, 27.0, 27.1, 27.2, 27.3, 27.4, 27.5, 27.6, 27.7, 27.8, 27.9, 28.0, 28.1, 28.2, 28.3, 28.4, 28.5, 28.6, 28.7, 28.8, 28.9, 29.0, 29.2, 29.3, 29.5, 29.6, 29.7, 29.8, 29.9, 30.0, 30.1, 30.2, 30.3, 30.4, 30.5, 30.7, 30.8, 30.9, 31.0, 31.1, 31.2, 31.3, 31.6, 31.9, 32.0, 32.1, 32.2, 32.3, 32.4, 32.5, 32.6, 32.7, 32.8, 32.9, 33.1, 33.2, 33.3, 33.5, 33.6, 33.7, 33.8, 33.9, 34.0, 34.1, 34.2, 34.3, 34.4, 34.5, 34.6, 34.7, 34.8, 34.9, 35.0, 35.1, 35.2, 35.3, 35.4, 35.5, 35.6, 35.7, 35.8, 35.9, 36.0, 36.1, 36.2, 36.3, 36.4, 36.5, 36.6, 36.7, 36.8, 36.9, 37.0, 37.1, 37.2, 37.3, 37.4, 37.5, 37.6, 37.7, 37.8, 37.9, 38.0, 38.1, 38.2, 38.3, 38.4, 38.5, 38.6, 38.7, 38.8, 38.9, 39.0, 39.1, 39.2, 39.3, 39.4, 39.5, 39.6, 39.7, 39.8, 39.9, 40.0, 40.1, 40.2, 40.5, 40.6, 40.7, 40.8, 40.9, 41.0, 41.2, 41.3, 41.5, 41.8, 42.0, 42.1, 42.2, 42.3, 42.4, 42.6, 42.7, 42.8, 42.9, 43.1, 43.2, 43.3, 43.4, 43.5, 43.6, 44.0, 44.1, 44.2, 44.5, 44.6, 45.0, 45.2, 45.3, 45.4, 45.5, 45.6, 45.7, 45.8, 46.1, 46.2, 46.3, 46.5, 46.7, 46.8, 47.9, 48.3, 48.8, 49.3, 49.6, 49.7, 50.0, 52.3, 52.9, 53.2, 55.0, 57.3, 59.4, 67.1]\n",
      "*******************************************************\n",
      "DiabetesPedigreeFunction [0.078, 0.084, 0.085, 0.088, 0.089, 0.092, 0.096, 0.1, 0.101, 0.102, 0.107, 0.108, 0.115, 0.118, 0.121, 0.122, 0.123, 0.126, 0.127, 0.128, 0.129, 0.13, 0.133, 0.134, 0.135, 0.136, 0.137, 0.138, 0.14, 0.141, 0.142, 0.143, 0.144, 0.145, 0.147, 0.148, 0.149, 0.15, 0.151, 0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16, 0.161, 0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.17, 0.171, 0.173, 0.174, 0.175, 0.176, 0.177, 0.178, 0.179, 0.18, 0.181, 0.182, 0.183, 0.186, 0.187, 0.188, 0.189, 0.19, 0.191, 0.192, 0.194, 0.196, 0.197, 0.198, 0.199, 0.2, 0.201, 0.203, 0.204, 0.205, 0.206, 0.207, 0.209, 0.21, 0.212, 0.215, 0.217, 0.218, 0.219, 0.22, 0.221, 0.222, 0.223, 0.225, 0.226, 0.227, 0.229, 0.23, 0.231, 0.232, 0.233, 0.234, 0.235, 0.236, 0.237, 0.238, 0.239, 0.24, 0.241, 0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.251, 0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26, 0.261, 0.262, 0.263, 0.264, 0.265, 0.267, 0.268, 0.269, 0.27, 0.271, 0.272, 0.277, 0.278, 0.279, 0.28, 0.282, 0.283, 0.284, 0.285, 0.286, 0.287, 0.289, 0.29, 0.292, 0.293, 0.294, 0.295, 0.296, 0.297, 0.299, 0.3, 0.302, 0.303, 0.304, 0.305, 0.306, 0.307, 0.313, 0.314, 0.315, 0.317, 0.318, 0.319, 0.323, 0.324, 0.325, 0.326, 0.328, 0.329, 0.33, 0.331, 0.332, 0.334, 0.335, 0.336, 0.337, 0.338, 0.34, 0.341, 0.342, 0.343, 0.344, 0.345, 0.346, 0.347, 0.349, 0.351, 0.352, 0.355, 0.356, 0.358, 0.361, 0.362, 0.364, 0.365, 0.366, 0.368, 0.37, 0.371, 0.374, 0.375, 0.376, 0.378, 0.38, 0.381, 0.382, 0.383, 0.385, 0.388, 0.389, 0.391, 0.393, 0.394, 0.395, 0.396, 0.398, 0.399, 0.4, 0.401, 0.402, 0.403, 0.404, 0.407, 0.408, 0.409, 0.411, 0.412, 0.415, 0.416, 0.417, 0.419, 0.42, 0.421, 0.422, 0.423, 0.426, 0.427, 0.43, 0.431, 0.432, 0.433, 0.434, 0.435, 0.439, 0.441, 0.443, 0.444, 0.446, 0.447, 0.451, 0.452, 0.453, 0.454, 0.455, 0.457, 0.46, 0.463, 0.464, 0.465, 0.466, 0.467, 0.471, 0.472, 0.479, 0.482, 0.483, 0.484, 0.485, 0.487, 0.488, 0.491, 0.493, 0.495, 0.496, 0.497, 0.498, 0.499, 0.501, 0.502, 0.503, 0.507, 0.509, 0.51, 0.512, 0.514, 0.515, 0.516, 0.52, 0.525, 0.526, 0.527, 0.528, 0.529, 0.532, 0.534, 0.536, 0.537, 0.539, 0.542, 0.543, 0.545, 0.546, 0.547, 0.549, 0.551, 0.554, 0.557, 0.559, 0.56, 0.561, 0.564, 0.565, 0.569, 0.571, 0.572, 0.575, 0.578, 0.58, 0.582, 0.583, 0.586, 0.587, 0.588, 0.591, 0.593, 0.595, 0.597, 0.598, 0.6, 0.601, 0.605, 0.607, 0.61, 0.612, 0.613, 0.614, 0.615, 0.619, 0.624, 0.626, 0.627, 0.629, 0.63, 0.631, 0.637, 0.64, 0.645, 0.646, 0.647, 0.649, 0.652, 0.654, 0.655, 0.658, 0.66, 0.661, 0.665, 0.666, 0.672, 0.673, 0.674, 0.677, 0.678, 0.68, 0.682, 0.686, 0.687, 0.692, 0.693, 0.695, 0.696, 0.698, 0.699, 0.702, 0.703, 0.704, 0.705, 0.709, 0.711, 0.717, 0.718, 0.719, 0.721, 0.722, 0.725, 0.727, 0.73, 0.731, 0.732, 0.733, 0.734, 0.735, 0.738, 0.741, 0.742, 0.743, 0.744, 0.745, 0.748, 0.757, 0.759, 0.761, 0.766, 0.767, 0.771, 0.773, 0.785, 0.787, 0.801, 0.803, 0.804, 0.805, 0.808, 0.813, 0.816, 0.817, 0.821, 0.825, 0.826, 0.828, 0.831, 0.832, 0.833, 0.839, 0.84, 0.845, 0.851, 0.855, 0.856, 0.867, 0.871, 0.874, 0.875, 0.878, 0.88, 0.881, 0.886, 0.892, 0.893, 0.904, 0.905, 0.917, 0.925, 0.926, 0.93, 0.932, 0.933, 0.944, 0.947, 0.949, 0.955, 0.956, 0.962, 0.966, 0.968, 0.97, 0.997, 1.001, 1.021, 1.022, 1.034, 1.057, 1.072, 1.076, 1.095, 1.096, 1.101, 1.114, 1.127, 1.136, 1.138, 1.144, 1.154, 1.159, 1.162, 1.174, 1.182, 1.189, 1.191, 1.213, 1.222, 1.224, 1.251, 1.258, 1.268, 1.282, 1.292, 1.318, 1.321, 1.353, 1.39, 1.391, 1.394, 1.4, 1.441, 1.461, 1.476, 1.6, 1.698, 1.699, 1.731, 1.781, 1.893, 2.137, 2.288, 2.329, 2.42]\n",
      "*******************************************************\n",
      "Age [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 81]\n",
      "*******************************************************\n",
      "Outcome [0, 1]\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i,sorted(df[i].unique()))\n",
    "    print(\"*\"*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5723ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a2ca468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6    148.0           72.0           35.0     30.5  33.6   \n",
       "1            1     85.0           66.0           29.0     30.5  26.6   \n",
       "2            8    183.0           64.0           23.0     30.5  23.3   \n",
       "3            1     89.0           66.0           23.0     94.0  28.1   \n",
       "4            0    137.0           40.0           35.0    168.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2cbb5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f37c883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0739e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0807e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c44986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(6,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "581662cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 21ms/step - loss: 0.8598 - accuracy: 0.5244 - val_loss: 0.6977 - val_accuracy: 0.6948\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.8388 - accuracy: 0.5391 - val_loss: 0.6670 - val_accuracy: 0.7013\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7671 - accuracy: 0.5619 - val_loss: 0.6450 - val_accuracy: 0.7013\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7195 - accuracy: 0.5831 - val_loss: 0.6278 - val_accuracy: 0.7013\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.7311 - accuracy: 0.5977 - val_loss: 0.6127 - val_accuracy: 0.7013\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.7043 - accuracy: 0.5896 - val_loss: 0.5986 - val_accuracy: 0.7013\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.6880 - accuracy: 0.6042 - val_loss: 0.5881 - val_accuracy: 0.7013\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.7181 - accuracy: 0.5896 - val_loss: 0.5779 - val_accuracy: 0.7013\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5961 - val_loss: 0.5679 - val_accuracy: 0.7208\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.6368 - val_loss: 0.5592 - val_accuracy: 0.7208\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6466 - val_loss: 0.5526 - val_accuracy: 0.7208\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6515 - val_loss: 0.5465 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.6547 - val_loss: 0.5419 - val_accuracy: 0.7208\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6808 - val_loss: 0.5375 - val_accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.6482 - val_loss: 0.5330 - val_accuracy: 0.7338\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6384 - val_loss: 0.5302 - val_accuracy: 0.7338\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.6564 - val_loss: 0.5277 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.6824 - val_loss: 0.5240 - val_accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7003 - val_loss: 0.5203 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6922 - val_loss: 0.5170 - val_accuracy: 0.7273\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.6906 - val_loss: 0.5140 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7003 - val_loss: 0.5117 - val_accuracy: 0.7403\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.6873 - val_loss: 0.5097 - val_accuracy: 0.7403\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.6645 - val_loss: 0.5085 - val_accuracy: 0.7403\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.6775 - val_loss: 0.5069 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.6889 - val_loss: 0.5058 - val_accuracy: 0.7338\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7101 - val_loss: 0.5041 - val_accuracy: 0.7338\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.6840 - val_loss: 0.5026 - val_accuracy: 0.7338\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7052 - val_loss: 0.5010 - val_accuracy: 0.7338\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7068 - val_loss: 0.4994 - val_accuracy: 0.7338\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7134 - val_loss: 0.4986 - val_accuracy: 0.7338\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7101 - val_loss: 0.4974 - val_accuracy: 0.7208\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.6922 - val_loss: 0.4964 - val_accuracy: 0.7338\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.6889 - val_loss: 0.4950 - val_accuracy: 0.7403\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7068 - val_loss: 0.4941 - val_accuracy: 0.7338\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7182 - val_loss: 0.4934 - val_accuracy: 0.7338\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7117 - val_loss: 0.4924 - val_accuracy: 0.7338\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7134 - val_loss: 0.4922 - val_accuracy: 0.7338\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7052 - val_loss: 0.4913 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7101 - val_loss: 0.4906 - val_accuracy: 0.7403\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.6906 - val_loss: 0.4907 - val_accuracy: 0.7468\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7020 - val_loss: 0.4898 - val_accuracy: 0.7468\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7036 - val_loss: 0.4901 - val_accuracy: 0.7468\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7166 - val_loss: 0.4891 - val_accuracy: 0.7468\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7182 - val_loss: 0.4884 - val_accuracy: 0.7532\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7085 - val_loss: 0.4878 - val_accuracy: 0.7532\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7313 - val_loss: 0.4876 - val_accuracy: 0.7532\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7068 - val_loss: 0.4870 - val_accuracy: 0.7597\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5250 - accuracy: 0.7068 - val_loss: 0.4864 - val_accuracy: 0.7597\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7166 - val_loss: 0.4866 - val_accuracy: 0.7662\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7215 - val_loss: 0.4866 - val_accuracy: 0.7597\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7199 - val_loss: 0.4864 - val_accuracy: 0.7597\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7150 - val_loss: 0.4855 - val_accuracy: 0.7532\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5455 - accuracy: 0.7280 - val_loss: 0.4853 - val_accuracy: 0.7597\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5319 - accuracy: 0.7248 - val_loss: 0.4848 - val_accuracy: 0.7532\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7182 - val_loss: 0.4841 - val_accuracy: 0.7597\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5382 - accuracy: 0.7036 - val_loss: 0.4842 - val_accuracy: 0.7597\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5427 - accuracy: 0.7150 - val_loss: 0.4846 - val_accuracy: 0.7597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7036 - val_loss: 0.4848 - val_accuracy: 0.7597\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7231 - val_loss: 0.4852 - val_accuracy: 0.7597\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.6971 - val_loss: 0.4850 - val_accuracy: 0.7662\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7117 - val_loss: 0.4852 - val_accuracy: 0.7662\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7264 - val_loss: 0.4850 - val_accuracy: 0.7662\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7231 - val_loss: 0.4849 - val_accuracy: 0.7662\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7378 - val_loss: 0.4849 - val_accuracy: 0.7662\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7182 - val_loss: 0.4842 - val_accuracy: 0.7662\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7134 - val_loss: 0.4840 - val_accuracy: 0.7662\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.6987 - val_loss: 0.4836 - val_accuracy: 0.7662\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7215 - val_loss: 0.4838 - val_accuracy: 0.7727\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7231 - val_loss: 0.4838 - val_accuracy: 0.7727\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.7085 - val_loss: 0.4840 - val_accuracy: 0.7727\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.7329 - val_loss: 0.4838 - val_accuracy: 0.7727\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7443 - val_loss: 0.4835 - val_accuracy: 0.7727\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7362 - val_loss: 0.4835 - val_accuracy: 0.7727\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7362 - val_loss: 0.4830 - val_accuracy: 0.7727\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7296 - val_loss: 0.4834 - val_accuracy: 0.7662\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7231 - val_loss: 0.4828 - val_accuracy: 0.7662\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7280 - val_loss: 0.4827 - val_accuracy: 0.7662\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7248 - val_loss: 0.4824 - val_accuracy: 0.7662\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7280 - val_loss: 0.4826 - val_accuracy: 0.7662\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7459 - val_loss: 0.4817 - val_accuracy: 0.7662\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7427 - val_loss: 0.4822 - val_accuracy: 0.7727\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7492 - val_loss: 0.4819 - val_accuracy: 0.7727\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7378 - val_loss: 0.4817 - val_accuracy: 0.7727\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7362 - val_loss: 0.4822 - val_accuracy: 0.7662\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7410 - val_loss: 0.4819 - val_accuracy: 0.7662\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7345 - val_loss: 0.4820 - val_accuracy: 0.7662\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7313 - val_loss: 0.4820 - val_accuracy: 0.7662\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.7329 - val_loss: 0.4821 - val_accuracy: 0.7662\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7313 - val_loss: 0.4814 - val_accuracy: 0.7662\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.7459 - val_loss: 0.4809 - val_accuracy: 0.7727\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7231 - val_loss: 0.4809 - val_accuracy: 0.7727\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7231 - val_loss: 0.4807 - val_accuracy: 0.7727\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7296 - val_loss: 0.4806 - val_accuracy: 0.7727\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7329 - val_loss: 0.4804 - val_accuracy: 0.7727\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7394 - val_loss: 0.4803 - val_accuracy: 0.7662\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5197 - accuracy: 0.7264 - val_loss: 0.4803 - val_accuracy: 0.7662\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7199 - val_loss: 0.4806 - val_accuracy: 0.7662\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.5185 - accuracy: 0.7264 - val_loss: 0.4807 - val_accuracy: 0.7662\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.7459 - val_loss: 0.4810 - val_accuracy: 0.7597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d5fbf9f310>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8706f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "Requirement already satisfied: requests in e:\\anaconda3\\lib\\site-packages (from keras-tuner) (2.25.1)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging in e:\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2020.12.5)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b684837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ced9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model= tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(6,activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "    optimizers=hp.Choice('optimizer', values=['sgd','adadelta','adagrad','rmsprop','adam','nadam'])\n",
    "    model.compile(optimizer=optimizers, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5d0bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=kt.RandomSearch(build_model,objective=\"val_loss\",max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "227ef22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 28s]\n",
      "val_loss: 0.467526912689209\n",
      "\n",
      "Best val_loss So Far: 0.4619863033294678\n",
      "Total elapsed time: 00h 02m 29s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train,y_train,validation_data=(x_test,y_test),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "809457fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'rmsprop'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f9264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
